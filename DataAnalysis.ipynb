{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50567052-de3b-4666-966f-996c4660113b",
   "metadata": {},
   "source": [
    "To test: bigger range of edge values; 1 central node; different params: density, ...; different graph families; how algorithms behave for different terminals (maybe one of them gives more consistant results than other?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc44906-671d-48b9-8fe9-20dc60ef443d",
   "metadata": {},
   "source": [
    "###USE IT FOR GENERATED GRAPHS###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4bb29fba-2486-4ab4-b521-6813a44db967",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3926239588.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[146], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    cimport os\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cimport os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Folder paths\n",
    "folder_path = './results'\n",
    "# folder_path = './results/GraphInstances/B'\n",
    "output_folder = os.path.join(folder_path, 'plots')\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to create and save plots for costs and times\n",
    "def plot_data(df, file_name):\n",
    "    # Plot Costs by Number of Terminals\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for y in [\"TakahashiMatsuyamaCost\", \"KouMarkowskyBermanCost\"]:\n",
    "        sns.lineplot(data=df, x=\"NumberOfTerminals\", y=y, label=y)\n",
    "    plt.title(f\"Costs vs. Number of Terminals ({file_name})\")\n",
    "    plt.xlabel(\"Number of Terminals\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.legend()\n",
    "    output_file = os.path.join(output_folder, f\"{file_name}_terminals_cost.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Times by Number of Terminals\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for y in [\"TakahashiMatsuyamaTime\", \"KouMarkowskyBermanTime\"]:\n",
    "        sns.lineplot(data=df, x=\"NumberOfTerminals\", y=y, label=y)\n",
    "    plt.title(f\"Times vs. Number of Terminals ({file_name})\")\n",
    "    plt.xlabel(\"Number of Terminals\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.legend()\n",
    "    output_file = os.path.join(output_folder, f\"{file_name}_terminals_time.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Costs by Number of Nodes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for y in [\"TakahashiMatsuyamaCost\", \"KouMarkowskyBermanCost\"]:\n",
    "        sns.lineplot(data=df, x=\"NumberOfNodes\", y=y, label=y)\n",
    "    plt.title(f\"Costs vs. Number of Nodes ({file_name})\")\n",
    "    plt.xlabel(\"Number of Nodes\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.legend()\n",
    "    output_file = os.path.join(output_folder, f\"{file_name}_nodes_cost.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Times by Number of Nodes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for y in [\"TakahashiMatsuyamaTime\", \"KouMarkowskyBermanTime\"]:\n",
    "        sns.lineplot(data=df, x=\"NumberOfNodes\", y=y, label=y)\n",
    "    plt.title(f\"Times vs. Number of Nodes ({file_name})\")\n",
    "    plt.xlabel(\"Number of Nodes\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.legend()\n",
    "    output_file = os.path.join(output_folder, f\"{file_name}_nodes_time.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "# Iterate over all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.results'c):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Processing file: {filename}\")\n",
    "        plot_data(df, filename.split('.')[0])  # Pass filename without extension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd0d66-bf6d-44f7-b389-bc96c61fb72e",
   "metadata": {},
   "source": [
    "###USE IT FOR DATA BASE GRAPHS###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c60098c7-5f77-479a-ad3f-f4373439d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cc0a0c16-c6aa-4d98-9da5-3d4ecc99142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label(label):  \n",
    "    # Add spaces before capital letters (if not already present)\n",
    "    label = re.sub(r'(?<!\\s)(?=[A-Z])', ' ', label)\n",
    "    \n",
    "    # Replace long names with abbreviations\n",
    "    label = label.replace(\"Takahashi Matsuyama\", \"TM \")\n",
    "    label = label.replace(\"T M\", \"TM \")\n",
    "    label = label.replace(\"Dreyfus Wagner\", \"DW  \")\n",
    "    label = label.replace(\"D W\", \"DW  \")\n",
    "    label = label.replace(\"Kou Markowsky Berman\", \"KMB  \")\n",
    "    label = label.replace(\"K M B\", \"KMB  \")\n",
    "\n",
    "    # Replace ...\n",
    "    label = label.replace(\"Cost_ratio\", \"Approx-ratio \")\n",
    "    label = label.replace(\"worst case\", \"Worst Case\")\n",
    "    label = label.replace(\"_\", \" \")\n",
    "\n",
    "    # Remove \"Time\" from the label\n",
    "    label = label.replace(\"Time\", \"\")\n",
    "    label = label.replace(\"duration\", \"\")\n",
    "    label = label.replace(\"TimeToPerformance\", \"\")\n",
    "\n",
    "    # Remove extra spaces (if any)\n",
    "    label = re.sub(r'\\s+', ' ', label).strip()\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "20796186-3897-4f2c-8bb2-c81d2f5e300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdirectory_from_path(path):\n",
    "    # Extract the last part of the path (i.e., the folder name)\n",
    "    return os.path.basename(os.path.normpath(path))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "865b48c6-4b5d-4a79-adbe-3730b0b4bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_after_second_space(input_string):\n",
    "    # Step 1: Insert a space before each capital letter\n",
    "    modified_string = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', input_string)\n",
    "    \n",
    "    # Step 2: Split the string by spaces\n",
    "    split_parts = modified_string.split()\n",
    "    \n",
    "    # Step 3: Return the string after the second space (i.e., index 2 onward)\n",
    "    result = \" \".join(split_parts[2:])\n",
    "    return result[0].lower() + result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f9bebc28-4c38-4981-9b59-e49d8b57e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_approximation_ratio_table(df, x_col, y_cols, opt_col, output_folder=\"./tables\"):\n",
    "    \"\"\"\n",
    "    Generate a table for approximation ratios relative to `opt_col`.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input data.\n",
    "        x_col (str): The independent variable.\n",
    "        y_cols (list[str]): List of dependent variables for which to calculate approximation ratios.\n",
    "        opt_col (str): The column representing the \"Opt\" value.\n",
    "        output_folder (str): Path to save the LaTeX table.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated per-x_col approximation ratios.\n",
    "        pd.DataFrame: Overall approximation ratio summary.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Calculate approximation ratios\n",
    "    approx_ratios = df.copy()\n",
    "    for col in y_cols:\n",
    "        if col != \"worst_case\":\n",
    "            approx_ratios[f\"{col}_ratio\"] = approx_ratios[col] / approx_ratios[opt_col]\n",
    "    \n",
    "    # Per-x_col statistics\n",
    "    agg_funcs = {f\"{col}_ratio\": [\"mean\", \"min\", \"max\"] for col in y_cols if col != \"worst_case\"}\n",
    "    agg_funcs[\"worst_case\"] = [\"mean\", \"min\", \"max\"]\n",
    "    per_x_stats = approx_ratios.groupby(x_col).agg(agg_funcs)\n",
    "    per_x_stats.columns = [\"_\".join(col).strip() for col in per_x_stats.columns]\n",
    "    per_x_stats = per_x_stats.reset_index()\n",
    "    \n",
    "    # Apply preprocessing to column names in per_x_stats\n",
    "    per_x_stats.columns = [preprocess_label(col) for col in per_x_stats.columns]\n",
    "                           \n",
    "    # Overall statistics\n",
    "    overall_stats = {}\n",
    "    for col in y_cols:\n",
    "        if col != \"worst_case\":\n",
    "            ratio_col = f\"{col}_ratio\"\n",
    "            overall_stats[ratio_col] = {\n",
    "                \"mean\": approx_ratios[ratio_col].mean(),\n",
    "                \"min\": approx_ratios[ratio_col].min(),\n",
    "                \"max\": approx_ratios[ratio_col].max(),\n",
    "            }\n",
    "    # Include overall statistics for worst-case ratio\n",
    "    overall_stats[\"worst_case\"] = {\n",
    "        \"mean\": approx_ratios[\"worst_case\"].mean(),\n",
    "        \"min\": approx_ratios[\"worst_case\"].min(),\n",
    "        \"max\": approx_ratios[\"worst_case\"].max(),\n",
    "    }\n",
    "    overall_stats_df = pd.DataFrame(overall_stats).T.reset_index()\n",
    "    overall_stats_df.columns = [\"Metric\", \"Mean\", \"Min\", \"Max\"]\n",
    "\n",
    "    # Apply preprocessing to the \"Metric\" column\n",
    "    overall_stats_df[\"Metric\"] = overall_stats_df[\"Metric\"].apply(preprocess_label)\n",
    "\n",
    "\n",
    "    print(overall_stats_df)\n",
    "    # Apply preprocessing to column names in overall_stats_df\n",
    "    overall_stats_df.columns = [preprocess_label(col) for col in overall_stats_df.columns]\n",
    "\n",
    "    # Save per-x_col approximation ratios to a LaTeX table\n",
    "    per_x_table_path = os.path.join(output_folder, f\"approx_ratios_per_x_{x_col}.tex\")\n",
    "    with open(per_x_table_path, \"w\") as f:\n",
    "        f.write(per_x_stats.to_latex(index=False, float_format=\"%.3f\"))\n",
    "\n",
    "    # Save overall approximation ratios to a LaTeX table\n",
    "    overall_table_path = os.path.join(output_folder, f\"approx_ratios_overall_{x_col}.tex\")\n",
    "    with open(overall_table_path, \"w\") as f:\n",
    "        f.write(overall_stats_df.to_latex(index=False, float_format=\"%.3f\"))\n",
    "\n",
    "    print(f\"Approximation ratio tables saved: {per_x_table_path}, {overall_table_path}\")\n",
    "    return per_x_stats, overall_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3a5bd8d3-070b-4083-8cc1-1107b2ebda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_tables(df, x_col, y_cols, opt_col=None, output_folder=\"./tables\"):\n",
    "    \"\"\"\n",
    "    Generate summary statistics tables for y_cols and opt_col, including standard deviation of differences.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input data.\n",
    "        x_col (str): The independent variable.\n",
    "        y_cols (list[str]): List of dependent variables to process.\n",
    "        opt_col (str, optional): The column for \"Opt\" values, if available.\n",
    "        output_folder (str): Path to save the generated LaTeX tables.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Compute per-x_col statistics\n",
    "    agg_funcs = {col: [\"mean\", \"min\", \"max\"] for col in y_cols}\n",
    "\n",
    "    if opt_col:\n",
    "        agg_funcs[opt_col] = [\"mean\", \"min\", \"max\"]\n",
    "    \n",
    "    per_x_stats = df.groupby(x_col).agg(agg_funcs)\n",
    "    per_x_stats.columns = [\"_\".join(col).strip() for col in per_x_stats.columns]\n",
    "    per_x_stats = per_x_stats.reset_index()\n",
    "    \n",
    "    # Apply preprocessing to column names in per_x_stats\n",
    "    per_x_stats.columns = [preprocess_label(col) for col in per_x_stats.columns]\n",
    "\n",
    "    # Compute overall statistics across all x_col values\n",
    "    overall_stats = {}\n",
    "    for col in y_cols + ([opt_col] if opt_col else []):\n",
    "        overall_stats[col] = {\n",
    "            \"mean\": df[col].mean(),\n",
    "            \"min\": df[col].min(),\n",
    "            \"max\": df[col].max(),\n",
    "        }\n",
    "\n",
    "    overall_stats_df = pd.DataFrame(overall_stats).T.reset_index()\n",
    "    overall_stats_df.columns = [\"Metric\", \"Mean\", \"Min\", \"Max\"]\n",
    "\n",
    "    # Apply preprocessing to the \"Metric\" column\n",
    "    overall_stats_df[\"Metric\"] = overall_stats_df[\"Metric\"].apply(preprocess_label)\n",
    "\n",
    "    # Apply preprocessing to column names in overall_stats_df\n",
    "    overall_stats_df.columns = [preprocess_label(col) for col in overall_stats_df.columns]\n",
    "\n",
    "    # Save per-x_col statistics to a LaTeX table\n",
    "    per_x_table_path = os.path.join(output_folder, f\"per_x_stats_{x_col}.tex\")\n",
    "    with open(per_x_table_path, \"w\") as f:\n",
    "        f.write(per_x_stats.to_latex(index=False, float_format=\"%.3f\"))\n",
    "\n",
    "    # Save overall statistics to a LaTeX table\n",
    "    overall_table_path = os.path.join(output_folder, f\"overall_stats_{x_col}.tex\")\n",
    "    with open(overall_table_path, \"w\") as f:\n",
    "        f.write(overall_stats_df.to_latex(index=False, float_format=\"%.3f\"))\n",
    "\n",
    "    print(f\"Summary tables saved: {per_x_table_path}, {overall_table_path}\")\n",
    "    return per_x_stats, overall_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c1865f26-70be-4ea7-8aa5-8d4fa1e83fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "def plot_data(df, x_col, y_cols, title, x_label, y_label, output_file=None, opt_col=None, log_scale=False):\n",
    "    # Aggregate data by x_col (compute mean, min, max for each x)\n",
    "    agg_funcs = {col: [\"mean\", \"min\", \"max\"] for col in y_cols}\n",
    "    if opt_col:\n",
    "        agg_funcs[opt_col] = [\"mean\", \"min\", \"max\"]\n",
    "\n",
    "    # Group by x_col and compute aggregated values\n",
    "    aggregated_df = df.groupby(x_col).agg(agg_funcs)\n",
    "    aggregated_df.columns = [\"_\".join(col).strip() for col in aggregated_df.columns]\n",
    "    aggregated_df = aggregated_df.reset_index()\n",
    "\n",
    "    # Compute the worst-case values\n",
    "    if opt_col and \"worst_case\" in y_cols:\n",
    "        aggregated_df[\"worst_case_mean\"] *= aggregated_df[f\"{opt_col}_mean\"]\n",
    "        aggregated_df[\"worst_case_min\"] *= aggregated_df[f\"{opt_col}_min\"]\n",
    "        aggregated_df[\"worst_case_max\"] *= aggregated_df[f\"{opt_col}_max\"]\n",
    "            \n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Generate up to 10 distinct colors using a colormap\n",
    "    colormap = plt.get_cmap(\"tab10\", 10)  # Use \"tab10\" for distinct qualitative colors\n",
    "    color_list = [colormap(i) for i in range(10)]  # Generate a list of RGBA colors\n",
    "\n",
    "    y_cols_filtered = [col for col in y_cols if col not in [\"worst_case\"]]\n",
    "    for i, y in enumerate(y_cols_filtered):\n",
    "        # Assign a color based on the index (cycling if more than 10 functions)\n",
    "        base_color = color_list[i % 10]\n",
    "        \n",
    "        # Generate colors for mean, min, and max\n",
    "        mean_color = base_color  # Base color for the mean\n",
    "        min_color = (base_color[0], base_color[1], base_color[2], 0.7)  # Adjust alpha for transparency\n",
    "        max_color = (base_color[0], base_color[1], base_color[2], 1.0)  # Keep max fully opaque\n",
    "        \n",
    "        # Columns for aggregated data\n",
    "        mean_col = f\"{y}_mean\"\n",
    "        min_col = f\"{y}_min\"\n",
    "        max_col = f\"{y}_max\"\n",
    "        \n",
    "        # Plot mean line\n",
    "        sns.lineplot(data=aggregated_df, x=x_col, y=mean_col, label=f\"{preprocess_label(y)} (Mean)\", color=mean_color, errorbar=None)\n",
    "        \n",
    "        # Plot scatter points for min and max with their respective colors\n",
    "        plt.scatter(aggregated_df[x_col], aggregated_df[min_col], color=min_color, label=f\"{preprocess_label(y)} (Min)\", alpha=0.7)\n",
    "        plt.scatter(aggregated_df[x_col], aggregated_df[max_col], color=max_color, label=f\"{preprocess_label(y)} (Max)\", alpha=0.7)\n",
    "    \n",
    "    # Plot Opt column if available\n",
    "    if opt_col:\n",
    "        # Assign a unique color for the `opt_col` using an additional color index\n",
    "        opt_color = color_list[len(y_cols) % 10]  # Next color in the sequence\n",
    "    \n",
    "        # Generate colors for mean, min, and max\n",
    "        opt_mean_color = opt_color  # Base color for the mean\n",
    "        opt_min_color = (opt_color[0], opt_color[1], opt_color[2], 0.7)  # Adjust alpha for transparency\n",
    "        opt_max_color = (opt_color[0], opt_color[1], opt_color[2], 1.0)  # Keep max fully opaque\n",
    "    \n",
    "        # Columns for aggregated data\n",
    "        opt_mean_col = f\"{opt_col}_mean\"\n",
    "        opt_min_col = f\"{opt_col}_min\"\n",
    "        opt_max_col = f\"{opt_col}_max\"\n",
    "    \n",
    "        # Plot mean line\n",
    "        sns.lineplot(data=aggregated_df, x=x_col, y=opt_mean_col, label=f\"{opt_col} (Mean)\", linestyle=\"--\", color=opt_mean_color, errorbar=None)\n",
    "    \n",
    "        # Plot scatter points for min and max with their respective colors\n",
    "        plt.scatter(aggregated_df[x_col], aggregated_df[opt_min_col], color=opt_min_color, label=f\"{opt_col} (Min)\", alpha=0.7)\n",
    "        plt.scatter(aggregated_df[x_col], aggregated_df[opt_max_col], color=opt_max_color, label=f\"{opt_col} (Max)\", alpha=0.7)\n",
    "\n",
    "    # print(aggregated_df)\n",
    "    # Check if \"worst_case\" is in y_cols\n",
    "    if \"worst_case\" in y_cols:\n",
    "        # Plot the worst-case mean line\n",
    "        sns.lineplot(\n",
    "            data=aggregated_df,\n",
    "            x=x_col,\n",
    "            y=\"worst_case_mean\",\n",
    "            label=\"Worst Case (Mean)\",\n",
    "            color=\"black\",\n",
    "            linestyle=\"-\",\n",
    "            linewidth=2.5,\n",
    "            errorbar=None\n",
    "        )\n",
    "        \n",
    "        # Plot scatter points for worst-case min and max\n",
    "        plt.scatter(\n",
    "            aggregated_df[x_col],\n",
    "            aggregated_df[\"worst_case_min\"],\n",
    "            color=\"gray\",\n",
    "            label=\"Worst Case (Min)\",\n",
    "            alpha=0.7\n",
    "        )\n",
    "        plt.scatter(\n",
    "            aggregated_df[x_col],\n",
    "            aggregated_df[\"worst_case_max\"],\n",
    "            color=\"gray\",\n",
    "            label=\"Worst Case (Max)\",\n",
    "            alpha=1.0\n",
    "        )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c20d6-de92-421b-ac59-0e7c8111b231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1e4b5-dad4-4458-8a35-8dcde3fcd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_and_plot(\n",
    "    testset,\n",
    "    results_folder=\"./results/GraphInstances\",\n",
    "    base_url=\"https://steinlib.zib.de/showset.php?\",\n",
    "    output_folder=\"./overleaf-repo/images/plots\",\n",
    "    worst_case_param = \"NumberOfTerminals\",\n",
    "):\n",
    "\n",
    "    # Prepare paths and URL\n",
    "    testset_url = base_url + testset\n",
    "    folder_path = os.path.join(results_folder, testset)\n",
    "    output_folder = os.path.join(output_folder, testset)\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Fetch \"Opt\" values\n",
    "    response = requests.get(testset_url)\n",
    "    opt_values = {}\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table_rows = soup.find_all(\"tr\")[1:]\n",
    "        for row in table_rows:\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) > 5:\n",
    "                instance_name = cols[0].text.strip()\n",
    "                opt_value = cols[-1].text.strip().replace(\"\\xa0\", \"\")\n",
    "                opt_values[instance_name] = float(opt_value) if opt_value.isdigit() else None\n",
    "    else:\n",
    "        print(f\"Failed to fetch 'Opt' values for testset {testset}, status code: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    # Process results files\n",
    "    data_frames = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".results\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            instance_name = filename.split(\".\")[0]\n",
    "            if instance_name in opt_values:\n",
    "                df[\"Opt\"] = opt_values[instance_name]\n",
    "\n",
    "            time_columns = [col for col in df.columns if \"Time\" in col or \"duration\" in col]\n",
    "            for col in time_columns:\n",
    "                df[col] = df[col] / 1_000_000\n",
    "            data_frames.append(df)\n",
    "\n",
    "    if not data_frames:\n",
    "        print(f\"No .results files found in {folder_path}.\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    \n",
    "    # Calculate worst-case values\n",
    "    if worst_case_param in combined_df.columns:\n",
    "        combined_df[\"worst_case\"] = 2 * (1 - 1 / combined_df[worst_case_param])\n",
    "    else:\n",
    "        print(\"Column '{worst_case_param}' not found in the data.\")\n",
    "        return\n",
    "        \n",
    "    # Calculate \"time to performance\" for TM and KMB\n",
    "    combined_df[\"TMTimeToPerformance\"] = combined_df[\"TakahashiMatsuyamaCost\"] / combined_df[\"TakahashiMatsuyamaTime\"]\n",
    "    combined_df[\"KMBTimeToPerformance\"] = combined_df[\"KouMarkowskyBermanCost\"] / combined_df[\"KouMarkowskyBermanTime\"]\n",
    "\n",
    "\n",
    "    \n",
    "    # Extract the subdirectory (e.g., 'B' from './overleaf-repo/images/plots/B')\n",
    "    subdirectory = get_subdirectory_from_path(output_folder)\n",
    "\n",
    "    # Set the new output folder path for tables (e.g., './overleaf-repo/tables/B')\n",
    "    tables_output_folder = os.path.join(\"./overleaf-repo/tables\", subdirectory)\n",
    "\n",
    "    set_of_x_axes = [\"NumberOfTerminals\", \"NumberOfNodes\", \"NumberOfEdges\"]\n",
    "\n",
    "    for variable in set_of_x_axes:\n",
    "        # Generate plots\n",
    "        # Plot Costs by variable\n",
    "        plot_data(\n",
    "            combined_df,        \n",
    "            x_col=variable,\n",
    "            y_cols=[\"TakahashiMatsuyamaCost\", \"KouMarkowskyBermanCost\", \"worst_case\"],\n",
    "            title=f\"Costs vs {preprocess_label(variable)} ({testset})\",\n",
    "            x_label=preprocess_label(variable),\n",
    "            y_label=\"Cost\",\n",
    "            output_file=os.path.join(output_folder, f\"{split_after_second_space(variable)}_cost.png\"),\n",
    "            opt_col=\"Opt\"\n",
    "        )\n",
    "        # Generate tables with costs\n",
    "        per_x_stats, overall_stats_df = create_summary_tables(\n",
    "            combined_df,        \n",
    "            x_col=variable,\n",
    "            y_cols=[\"TakahashiMatsuyamaCost\", \"KouMarkowskyBermanCost\"],\n",
    "            opt_col=\"Opt\",\n",
    "            output_folder=tables_output_folder\n",
    "        )\n",
    "        # Generate tables with approximation ratio\n",
    "        per_x_ratios, overall_ratios = create_approximation_ratio_table(\n",
    "            df=combined_df,        \n",
    "            x_col=variable,\n",
    "            y_cols=[\"TakahashiMatsuyamaCost\", \"KouMarkowskyBermanCost\", \"worst_case\"],\n",
    "            opt_col=\"Opt\",\n",
    "            output_folder=tables_output_folder\n",
    "        )\n",
    "        # Plot Times by variable\n",
    "        plot_data(\n",
    "            combined_df,\n",
    "            x_col=variable,\n",
    "            y_cols=[\"TakahashiMatsuyamaTime\", \"KouMarkowskyBermanTime\"],\n",
    "            title=f\"Times vs {preprocess_label(variable)} ({testset})\",\n",
    "            x_label=preprocess_label(variable),\n",
    "            y_label=\"Time (seconds)\",\n",
    "            output_file=os.path.join(output_folder, f\"{split_after_second_space(variable)}_time.png\")\n",
    "        )\n",
    "        # Time to performence\n",
    "        plot_data(\n",
    "            combined_df,\n",
    "            x_col=variable,\n",
    "            y_cols=[\"TMTimeToPerformance\", \"KMBTimeToPerformance\"],\n",
    "            title=f\"Cost/Time vs {preprocess_label(variable)} ({testset})\",\n",
    "            x_label=preprocess_label(variable),\n",
    "            y_label=\"Cost/Time\",\n",
    "            output_file=os.path.join(output_folder, f\"{split_after_second_space(variable)}_CostToTime.png\")\n",
    "        )\n",
    "\n",
    "    # Additional plots for TMduration* and KMBduration*\n",
    "    tm_duration_columns = [col for col in combined_df.columns if col.startswith(\"TMduration\")]\n",
    "    kmb_duration_columns = [col for col in combined_df.columns if col.startswith(\"KMBduration\")]\n",
    "\n",
    "    for variable in set_of_x_axes:\n",
    "        # Inner Times\n",
    "        plot_data(\n",
    "            combined_df,        \n",
    "            x_col=variable,\n",
    "            y_cols=tm_duration_columns,\n",
    "            title=f\"TM Durations vs Number of Terminals ({testset})\",\n",
    "            x_label=preprocess_label(variable),\n",
    "            y_label=\"Time (seconds)\",\n",
    "            output_file=os.path.join(output_folder, f\"{split_after_second_space(variable)}_tm_durations.png\")\n",
    "        )\n",
    "    \n",
    "        plot_data(\n",
    "            combined_df,        \n",
    "            x_col=variable,\n",
    "            y_cols=kmb_duration_columns,\n",
    "            title=f\"KMB Durations vs Number of Terminals ({testset})\",\n",
    "            x_label=preprocess_label(variable),\n",
    "            y_label=\"Time (seconds)\",\n",
    "            output_file=os.path.join(output_folder, f\"{split_after_second_space(variable)}_kmb_durations.png\"),\n",
    "        )\n",
    "        \n",
    "        plot_data(\n",
    "            combined_df,        \n",
    "            x_col=variable,\n",
    "            y_cols=kmb_duration_columns,\n",
    "            title=f\"KMB Durations vs Number of Terminals ({testset})\",\n",
    "            x_label=preprocess_label(variable),\n",
    "            y_label=\"Time (seconds)\",\n",
    "            output_file=os.path.join(output_folder, f\"{split_after_second_space(variable)}_kmb_durations_log_scale.png\"),\n",
    "            log_scale=True\n",
    "        )\n",
    "\n",
    "    print(f\"All plots for testset {testset} have been generated in {output_folder}.\")\n",
    "    print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "92aefb92-5876-4632-8e95-aef90cf8be08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 4 elements, new values have 5 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m process_and_plot(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[184], line 88\u001b[0m, in \u001b[0;36mprocess_and_plot\u001b[0;34m(testset, results_folder, base_url, output_folder, worst_case_param)\u001b[0m\n\u001b[1;32m     77\u001b[0m plot_data(\n\u001b[1;32m     78\u001b[0m     combined_df,        \n\u001b[1;32m     79\u001b[0m     x_col\u001b[38;5;241m=\u001b[39mvariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m     opt_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Generate tables with costs\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m per_x_stats, overall_stats_df \u001b[38;5;241m=\u001b[39m create_summary_tables(\n\u001b[1;32m     89\u001b[0m     combined_df,        \n\u001b[1;32m     90\u001b[0m     x_col\u001b[38;5;241m=\u001b[39mvariable,\n\u001b[1;32m     91\u001b[0m     y_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTakahashiMatsuyamaCost\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKouMarkowskyBermanCost\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     92\u001b[0m     opt_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     output_folder\u001b[38;5;241m=\u001b[39mtables_output_folder\n\u001b[1;32m     94\u001b[0m )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Generate tables with approximation ratio\u001b[39;00m\n\u001b[1;32m     96\u001b[0m per_x_ratios, overall_ratios \u001b[38;5;241m=\u001b[39m create_approximation_ratio_table(\n\u001b[1;32m     97\u001b[0m     df\u001b[38;5;241m=\u001b[39mcombined_df,        \n\u001b[1;32m     98\u001b[0m     x_col\u001b[38;5;241m=\u001b[39mvariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     output_folder\u001b[38;5;241m=\u001b[39mtables_output_folder\n\u001b[1;32m    102\u001b[0m )\n",
      "Cell \u001b[0;32mIn[182], line 39\u001b[0m, in \u001b[0;36mcreate_summary_tables\u001b[0;34m(df, x_col, y_cols, opt_col, output_folder)\u001b[0m\n\u001b[1;32m     32\u001b[0m     overall_stats[col] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: df[col]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m: df[col]\u001b[38;5;241m.\u001b[39mmin(),\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m: df[col]\u001b[38;5;241m.\u001b[39mmax(),\n\u001b[1;32m     36\u001b[0m     }\n\u001b[1;32m     38\u001b[0m overall_stats_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(overall_stats)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m---> 39\u001b[0m overall_stats_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to the \"Metric\" column\u001b[39;00m\n\u001b[1;32m     42\u001b[0m overall_stats_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m overall_stats_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_label)\n",
      "File \u001b[0;32m~/anaconda3/envs/ET/lib/python3.12/site-packages/pandas/core/generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ET/lib/python3.12/site-packages/pandas/core/generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/ET/lib/python3.12/site-packages/pandas/core/internals/managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/envs/ET/lib/python3.12/site-packages/pandas/core/internals/base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 4 elements, new values have 5 elements"
     ]
    }
   ],
   "source": [
    "process_and_plot(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181f0cb-8038-4a38-825b-3612e6890b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f86cf3-1548-4794-a9b5-fb2d2e656134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
